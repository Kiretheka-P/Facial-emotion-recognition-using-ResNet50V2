{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f038211-3d09-40a3-9b3f-06151925bdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.applications import ResNet50V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94aa2cce-cb76-4051-aeab-94aa246ccd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to count classes in the dataset\n",
    "def Classes_Count(path, name):\n",
    "    Classes_Dict = {}\n",
    "    for Class in os.listdir(path):\n",
    "        Full_Path = os.path.join(path, Class)\n",
    "        Classes_Dict[Class] = len(os.listdir(Full_Path))\n",
    "    df = pd.DataFrame(Classes_Dict, index=[name])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0a278d8-8a05-4cf5-b301-c4337d4515b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data paths\n",
    "train_dir = 'F:\\\\PG\\\\Semester 2\\\\MP II\\\\Dataset\\\\train\\\\'\n",
    "test_dir = 'F:\\\\PG\\\\Semester 2\\\\MP II\\\\Dataset\\\\test\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6260cf89-b608-47d6-83b1-19d9a05f8214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>happy</th>\n",
       "      <td>7215</td>\n",
       "      <td>1774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>4965</td>\n",
       "      <td>1233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sad</th>\n",
       "      <td>4830</td>\n",
       "      <td>1247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fear</th>\n",
       "      <td>4097</td>\n",
       "      <td>1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>angry</th>\n",
       "      <td>3995</td>\n",
       "      <td>958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>surprise</th>\n",
       "      <td>3171</td>\n",
       "      <td>831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disgust</th>\n",
       "      <td>436</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          train  test\n",
       "happy      7215  1774\n",
       "neutral    4965  1233\n",
       "sad        4830  1247\n",
       "fear       4097  1024\n",
       "angry      3995   958\n",
       "surprise   3171   831\n",
       "disgust     436   111"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count classes in train and test datasets\n",
    "Train_Count = Classes_Count(train_dir, 'train').transpose().sort_values(by=\"train\", ascending=False)\n",
    "Test_Count = Classes_Count(test_dir, 'test').transpose().sort_values(by=\"test\", ascending=False)\n",
    "pd.concat([Train_Count, Test_Count], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1c571550-7113-4d4f-83f3-f0c8d7f56416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image parameters\n",
    "img_shape = 224\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8b44a0bf-dced-4f89-9b1e-a77ed0880072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28709 images belonging to 7 classes.\n",
      "Found 7178 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "# ImageDataGenerator for train and test data\n",
    "train_preprocessor = ImageDataGenerator(\n",
    "    rescale=1 / 255.,\n",
    "    rotation_range=10,\n",
    "    zoom_range=0.2,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    ")\n",
    "\n",
    "test_preprocessor = ImageDataGenerator(rescale=1 / 255.)\n",
    "\n",
    "train_data = train_preprocessor.flow_from_directory(\n",
    "    train_dir,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(img_shape, img_shape),\n",
    "    color_mode='rgb',\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    subset='training',\n",
    ")\n",
    "\n",
    "test_data = test_preprocessor.flow_from_directory(\n",
    "    test_dir,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(img_shape, img_shape),\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=False,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "33bc512d-3bcf-4afc-a7da-7e3dbf4bea7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained ResNet50V2 model\n",
    "ResNet50V2_base = ResNet50V2(input_shape=(img_shape, img_shape, 3),\n",
    "                             include_top=False,\n",
    "                             weights='imagenet'\n",
    "                             )\n",
    "\n",
    "# Freeze all layers except last 50\n",
    "ResNet50V2_base.trainable = True\n",
    "for layer in ResNet50V2_base.layers[:-50]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Custom model using ResNet50V2\n",
    "def Create_Custom_ResNet50V2_Model():\n",
    "    model = Sequential([\n",
    "        ResNet50V2_base,\n",
    "        Dropout(0.25),\n",
    "        BatchNormalization(),\n",
    "        Flatten(),\n",
    "        Dense(64, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(7, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "ResNet50V2_Model = Create_Custom_ResNet50V2_Model()\n",
    "ResNet50V2_Model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e443542c-5c4f-4741-9e75-d055eb36cd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "checkpoint_path = \"ResNet50V2_Model_Checkpoint.keras\"\n",
    "Checkpoint = ModelCheckpoint(checkpoint_path, monitor=\"val_accuracy\", save_best_only=True)\n",
    "Early_Stopping = EarlyStopping(monitor='val_accuracy', patience=7, restore_best_weights=True, verbose=1)\n",
    "Reducing_LR = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, verbose=1)\n",
    "\n",
    "callbacks = [Early_Stopping, Reducing_LR]\n",
    "\n",
    "steps_per_epoch = train_data.n // train_data.batch_size\n",
    "validation_steps = test_data.n // test_data.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7971596a-7098-4f7a-b684-6a61388b8312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4249s\u001b[0m 9s/step - accuracy: 0.4121 - loss: 1.8249 - val_accuracy: 0.5582 - val_loss: 1.1871 - learning_rate: 0.0010\n",
      "Epoch 2/30\n",
      "\u001b[1m  1/448\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m50:30\u001b[0m 7s/step - accuracy: 0.5000 - loss: 1.4981"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python311\\Lib\\contextlib.py:155: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 16ms/step - accuracy: 0.5000 - loss: 1.4981 - val_accuracy: 0.7000 - val_loss: 0.6085 - learning_rate: 0.0010\n",
      "Epoch 3/30\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29054s\u001b[0m 65s/step - accuracy: 0.5547 - loss: 1.2321 - val_accuracy: 0.5862 - val_loss: 1.0966 - learning_rate: 0.0010\n",
      "Epoch 4/30\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.6250 - loss: 1.1920 - val_accuracy: 1.0000 - val_loss: 0.2553 - learning_rate: 0.0010\n",
      "Epoch 5/30\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4072s\u001b[0m 9s/step - accuracy: 0.5508 - loss: 1.2721 - val_accuracy: 0.5968 - val_loss: 1.0737 - learning_rate: 0.0010\n",
      "Epoch 6/30\n",
      "\u001b[1m  1/448\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m58:18\u001b[0m 8s/step - accuracy: 0.5000 - loss: 1.2789\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.5000 - loss: 1.2789 - val_accuracy: 0.8000 - val_loss: 0.4703 - learning_rate: 0.0010\n",
      "Epoch 7/30\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5059s\u001b[0m 11s/step - accuracy: 0.6031 - loss: 1.0971 - val_accuracy: 0.6242 - val_loss: 0.9971 - learning_rate: 2.0000e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m  1/448\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:11:49\u001b[0m 10s/step - accuracy: 0.6250 - loss: 0.9436\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.6250 - loss: 0.9436 - val_accuracy: 1.0000 - val_loss: 0.2595 - learning_rate: 2.0000e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4277s\u001b[0m 10s/step - accuracy: 0.6295 - loss: 1.0368 - val_accuracy: 0.6336 - val_loss: 0.9826 - learning_rate: 4.0000e-05\n",
      "Epoch 10/30\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.6719 - loss: 1.0151 - val_accuracy: 1.0000 - val_loss: 0.1827 - learning_rate: 4.0000e-05\n",
      "Epoch 11/30\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4531s\u001b[0m 10s/step - accuracy: 0.6312 - loss: 1.0128 - val_accuracy: 0.6385 - val_loss: 0.9735 - learning_rate: 4.0000e-05\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n"
     ]
    }
   ],
   "source": [
    "ResNet50V2_history = ResNet50V2_Model.fit(train_data, validation_data=test_data, epochs=30, batch_size=batch_size,\n",
    "                                           callbacks=callbacks, steps_per_epoch=steps_per_epoch,\n",
    "                                           validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "761dfbdf-e273-42e0-91a5-6e22c295b8c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m476s\u001b[0m 4s/step - accuracy: 0.4240 - loss: 1.4456\n",
      "Test Loss: 1.09750\n",
      "Test Accuracy: 58.60%\n"
     ]
    }
   ],
   "source": [
    "ResNet50V2_Score = ResNet50V2_Model.evaluate(test_data)\n",
    "print(\"Test Loss: {:.5f}\".format(ResNet50V2_Score[0]))\n",
    "print(\"Test Accuracy: {:.2f}%\".format(ResNet50V2_Score[1] * 100))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
